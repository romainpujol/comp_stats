{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" Je t'ai mis ce que donne le plot quand nb_trials = 15 et iterations = 500. Le programme prend \\nson petit temps √† tourner. \\n\\nParameters   Relative Bias     Relative RMSE\\n  ln(P1)          0.02              0.02\\n  ln(P2)          0.02              0.02\\n  ln(ùúÜ1)          0.02              0.08\\n  ln(ùúÜ2)          0.11              0.11\\n  omega1          0.54              0.67\\n  omega2          0.45              0.55\\n  omega3          0.06              0.14\\n  omega4          0.88              0.89\\n  sigma           0.20              0.21\\n  \\n\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "############################################################################\n",
    "#\n",
    "# Romain Pujol, Lilian Welschinger\n",
    "# Computational statistics, MVA\n",
    "# Extension of the SAEM algorithm to left-censored data in nonlinear\n",
    "# mixed-effects model: Application to HIV dynamics model\n",
    "#\n",
    "############################################################################\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import multivariate_normal, norm\n",
    "#np.random.seed(1)\n",
    "\n",
    "def f(t,phi):\n",
    "    return np.log10(np.exp(phi[0])*np.exp(-np.exp(phi[2])*t)+np.exp(phi[1])*np.exp(-np.exp(phi[3])*t))\n",
    "\n",
    "def viral_load(n_patient,mu=np.array([12,8,np.log(0.5),np.log(0.05)]),w=0.3*np.ones(4),sigma=0.065,table_t=np.array([1,3,7,14,28,56])):\n",
    "    #returns the viral load of n_patient during the time table table_t, simulation of the data\n",
    "    #also returns the real phi vector, will be useful for accuracy metrics\n",
    "    t = len(table_t)\n",
    "    viral_load_ = np.zeros((n_patient,t))\n",
    "    phis = np.zeros((n_patient,4))\n",
    "    for i in range(n_patient):\n",
    "        epsilon = np.random.normal(0,np.sqrt(sigma),t)\n",
    "        phi_patient = mu + np.random.multivariate_normal(np.zeros(4),np.diag(w))\n",
    "        phis[i,:]=phi_patient\n",
    "        for j in range(t):\n",
    "            viral_load_[i,j]=f(table_t[j],phi_patient)+epsilon[j]\n",
    "    return viral_load_,phis\n",
    "\n",
    "def plot_viral_load(viral_load_,real_mu,approx_mu,table_t=np.array([1,3,7,14,28,56])):\n",
    "    #takes in input the output of the viral_load function and the time table, then plots a graph representing the viral load\n",
    "    shape = viral_load_.shape\n",
    "    n_patient = shape[0]\n",
    "    time = shape[1]\n",
    "\n",
    "    for i in range(n_patient):\n",
    "        plt.scatter(table_t,viral_load_[i,:],color='blue',marker='+',s=5)\n",
    "\n",
    "    trace = np.log10(np.exp(real_mu[0])*np.exp(-0.5*table_t)+np.exp(real_mu[1])*np.exp(-0.05*table_t))\n",
    "    plt.plot(table_t,trace,label=\"Real trend\")\n",
    "    trace_app = np.log10(np.exp(approx_mu[0])*np.exp(-np.exp(approx_mu[2])*table_t)+np.exp(approx_mu[1])*np.exp(-np.exp(approx_mu[3])*table_t))\n",
    "    plt.plot(table_t,trace_app,label=\"Approximate trend\")\n",
    "    plt.xlim(0,57)\n",
    "    plt.hlines(2.6,0,57,colors='red',linestyles='--',label=\"LOQ\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    return\n",
    " \n",
    "def viral_load_to_censored(viral_load_,loq=2.6):\n",
    "    #input : viral_load \n",
    "    #output : censored indexes\n",
    "\n",
    "    index = np.ones(viral_load_.shape)\n",
    "    for i in range(viral_load_.shape[0]):\n",
    "        for j in range(viral_load_.shape[1]):\n",
    "            if viral_load_[i,j]<loq:\n",
    "                index[i,j]=0\n",
    "\n",
    "    return index\n",
    "    \n",
    "def p(phi,i,y,mu_current,omega_current,sigma_current,table_t=np.array([1,3,7,14,28,56])):\n",
    "    #y represents the whole matrix (with imputed values of ycensored)\n",
    "    #i represents the line we use\n",
    "    N,K = y.shape\n",
    "    #if omega_current == 0:\n",
    "    #    print(\"error, omega = 0\")\n",
    "    #else:\n",
    "    matrix = np.diag(1/omega_current)\n",
    "    value =-(phi-mu_current).T @ matrix @ (phi-mu_current)/2\n",
    "    for j in range(K):\n",
    "        value -= (1/(2*sigma_current))*((y[i,j]-f(table_t[j],phi))**2)\n",
    "\n",
    "    return np.exp(value)\n",
    "\n",
    "def proposition_prior(current_mu,current_omega,current_phi,current_sigma,current_y):\n",
    "    #current_mu, current_omega are two parameters that are being constructed in the procedure\n",
    "    N,K = current_phi.shape\n",
    "    update = np.zeros((N,K))\n",
    "    for i in range(N):\n",
    "        proposition_=np.random.multivariate_normal(current_mu,np.diag(current_omega))\n",
    "        q_ratio = multivariate_normal.pdf(proposition_,current_mu,np.diag(current_omega))/multivariate_normal.pdf(current_phi[i,:],current_mu,np.diag(current_omega))\n",
    "        acc_rate = np.exp(np.minimum(0,np.log(q_ratio)+np.log(p(proposition_,i,current_y,current_mu,current_omega,current_sigma))-np.log(p(current_phi[i,:],i,current_y,current_mu,current_omega,current_sigma))))\n",
    "        u = np.random.rand()\n",
    "        if u<acc_rate:\n",
    "            update[i,:]=proposition_\n",
    "        else:\n",
    "            update[i,:]=current_phi[i,:]\n",
    "    return update\n",
    "\n",
    "def proposition_multidim_rw(current_phi,current_omega,current_sigma,current_y,current_mu,lambd=1):\n",
    "    #multidimensional random walk proposal\n",
    "    N,K = current_phi.shape\n",
    "    proposition = np.zeros((N,K))\n",
    "    for i in range(N):\n",
    "        proposition_=np.random.multivariate_normal(current_phi[i,:],lambd*np.diag(current_omega))\n",
    "        acc_rate = np.exp(np.minimum(0,np.log(p(proposition_,i,current_y,current_mu,current_omega,current_sigma))-np.log(p(current_phi[i,:],i,current_y,current_mu,current_omega,current_sigma))))\n",
    "        u = np.random.rand()\n",
    "        if u<acc_rate:\n",
    "            proposition[i,:]=proposition_\n",
    "        else:\n",
    "            proposition[i,:]=current_phi[i,:]\n",
    "    return proposition\n",
    "\n",
    "def proposition_unidim_rw(current_phi,lambd,current_y,current_mu,current_omega,current_sigma):\n",
    "    #unidimensional random walk proposal\n",
    "    N,K = current_phi.shape\n",
    "    proposition = np.copy(current_phi)\n",
    "    for i in range(N):\n",
    "        line_i = np.copy(current_phi[i,:])\n",
    "        for j in range(K):\n",
    "            step = np.random.normal(0,lambd)\n",
    "            proposition[i,j]+=step\n",
    "            acc_rate = np.minimum(1,p(proposition[i,:],i,current_y,current_mu,current_omega,current_sigma)/p(line_i,i,current_y,current_mu,current_omega,current_sigma))\n",
    "            u = np.random.rand()\n",
    "            if u>acc_rate:\n",
    "                proposition[i,j]=line_i[j]\n",
    "    \n",
    "    return proposition\n",
    "\n",
    "\n",
    "def hm_algorithm_update(current_y,current_phi,current_omega,current_mu,current_sigma,lambd,method):\n",
    "    if method==1:\n",
    "        update= proposition_prior(current_mu,current_omega,current_phi,current_sigma,current_y)\n",
    "    elif method==2:\n",
    "        update=proposition_multidim_rw(current_phi,current_omega,current_sigma,current_y,current_mu,lambd=1)\n",
    "    elif method==3:\n",
    "        update=proposition_unidim_rw(current_phi,lambd,current_y,current_mu,current_omega,current_sigma)\n",
    "    return update    \n",
    "    \n",
    "\n",
    "\n",
    "def update_y_cens(phi,t,sigma,LOQ):\n",
    "    m=f(t,phi) \n",
    "    C=(f(t,phi)-LOQ)/sigma\n",
    "    alpha = (C+np.sqrt(C**2+4))/2\n",
    "    u = np.random.rand()\n",
    "    x = (-1/alpha)*np.log(1-u)+C\n",
    "    proba = np.exp(-(x-alpha)**2/2)\n",
    "    u = np.random.rand()\n",
    "    while u > proba :\n",
    "        u = np.random.rand()\n",
    "        x = -1/alpha * np.log(1 - u) + C\n",
    "        proba = np.exp(-(x-alpha)**2/2)\n",
    "        u = np.random.rand()\n",
    "    y = m - sigma*x\n",
    "    return y\n",
    "\n",
    "\n",
    "def S(y,phi,time_t=np.array([1,3,7,14,28,56])):\n",
    "    N,K = y.shape\n",
    "    S_1 = np.sum(phi,axis=0)\n",
    "    S_2 = np.sum(phi**2,axis=0)\n",
    "    S_3=0\n",
    "    for i in range(N):\n",
    "        for j in range(K):\n",
    "            S_3+=((y[i,j]-f(time_t[j],phi[i,:]))**2)\n",
    "        \n",
    "    return S_1,S_2,S_3\n",
    "\n",
    "def update_s(s_m,gamma,y,phi):\n",
    "    s_1,s_2,s_3 = S(y,phi)\n",
    "    if gamma == 1:\n",
    "        return s_1,s_2,s_3\n",
    "    else:\n",
    "        return s_m[0] +gamma*(s_1-s_m[0]),s_m[1] +gamma*(s_2-s_m[1]),s_m[2] +gamma*(s_3-s_m[2])\n",
    "\n",
    "\n",
    "def update_mu_w_sigma(S_1,S_2,S_3,N,K):\n",
    "    new_mu = S_1/N\n",
    "    new_w = S_2/N- (new_mu)**2\n",
    "    new_sigma = S_3/(N*K)\n",
    "    return new_mu,new_w,new_sigma\n",
    "\n",
    "def SAEM(omega_0,mu_0,sigma_0,y_0,phi_0,s_0,iteration,method,lambd=1,t=np.array([1,3,7,14,28,56]),LOQ=2.6,M1 = 1000):\n",
    "\n",
    "    y = np.copy(y_0)\n",
    "    phi = np.copy(phi_0)\n",
    "    omega = np.copy(omega_0)\n",
    "    mu = np.copy(mu_0)\n",
    "    sigma = np.copy(sigma_0)\n",
    "    s = s_0\n",
    "    N,K = y.shape\n",
    "    mu_evolve = [mu]\n",
    "    omega_evolve = [omega]\n",
    "    sigma_evolve = [sigma]\n",
    "\n",
    "    index_censored = np.where(y <= LOQ)\n",
    "\n",
    "    for i in range(iteration):\n",
    "        #########################################\n",
    "        # S step : simulation of the missing data\n",
    "        #########################################\n",
    "\n",
    "        #simulate phi\n",
    "        phi = hm_algorithm_update(y,phi,omega,mu,sigma,lambd,method)\n",
    "        #simulate y_censored\n",
    "        for k,j in zip(index_censored[0],index_censored[1]):\n",
    "            y[k,j] = update_y_cens(phi[k,:],t[j],sigma,LOQ)\n",
    "\n",
    "        #########################################\n",
    "        # SA step \n",
    "        #########################################\n",
    "\n",
    "        #update s\n",
    "        if i <= M1:\n",
    "            gamma = 1\n",
    "        else:\n",
    "            gamma = 1/(i-M1)\n",
    "        \n",
    "        s = update_s(s,gamma,y,phi)\n",
    "\n",
    "        #########################################\n",
    "        # M step \n",
    "        #########################################\n",
    "\n",
    "        mu,omega,sigma = update_mu_w_sigma(s[0],s[1],s[2],N,K)\n",
    "        mu_evolve.append(mu)\n",
    "        sigma_evolve.append(sigma)\n",
    "        omega_evolve.append(omega)\n",
    "\n",
    "    return mu,omega,sigma,y,mu_evolve,sigma_evolve,omega_evolve\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "################################################################\n",
    "# Real parameters and data\n",
    "################################################################\n",
    "\n",
    "mu_=np.array([12,8,np.log(0.5),np.log(0.05)])\n",
    "w=0.3*np.ones(4)\n",
    "sigma=0.065\n",
    "table_t=np.array([1,3,7,14,28,56])\n",
    "y,phi = viral_load(100)\n",
    "\n",
    "\n",
    "################################################################\n",
    "# Input of SAEM, censored data\n",
    "################################################################\n",
    "\n",
    "starting_y=np.copy(y)\n",
    "N,K = starting_y.shape\n",
    "for i in range(N):\n",
    "    for j in range(K):\n",
    "        if starting_y[i,j]<2.6:\n",
    "            ##############################################################\n",
    "            # ici on peut exp√©rimetner avec la valeur √† mettre au d√©part\n",
    "            #par exemple 2.6, 1.3, 0\n",
    "            #ou d'autres id√©es un peu plus int√©ressante en calculant\n",
    "            #l'√©cart avec 2.6 avec la valeur pr√©c√©dente,\n",
    "            #on peut peut √™tre imputer une valeur intelligente :\n",
    "            # si la valeur d'avant est 2.7, on peut se douter que celle\n",
    "            # d'apr√®s sera vraisemblablement plus faible que si la valeur\n",
    "            #pr√©c√©dente √©tait 3.6\n",
    "            ##############################################################\n",
    "            starting_y[i,j]=2.6 \n",
    "\n",
    "\n",
    "\n",
    "#######################################################################\n",
    "# ici on peut aussi essayer de donner des valeurs int√©ressantes\n",
    "# pour certaines variables, j'y ai pas pens√© encore\n",
    "#j'ai juste mis des trucs al√©atoires proche de la vraie valeur\n",
    "#######################################################################\n",
    "\n",
    "phi_test = phi + 2*(np.random.rand(4))-1\n",
    "s_0 = (np.zeros(4), np.zeros(4), 0)\n",
    "starting_mu=mu_+4*(np.random.rand(4))-2\n",
    "starting_w= w +0.2*(np.random.rand(4))-0.1\n",
    "starting_sigma = 0.4\n",
    "\n",
    "\n",
    "#probl√®me avec la m√©thode 1 dans la partie d'exploration : quand on est en dessous de M1 parce qu'on passe sur une matrice\n",
    "#qui n'est plus SDP en faisant varier les valeurs de theta (donc les valeurs de omega), \n",
    "#en revanche, les m√©thodes 2 et 3 fonctionnent plut√¥t bien, je n'ai pas vu de probl√®me\n",
    "\n",
    "method = 2\n",
    "\"\"\"\n",
    "√Ä la ligne suivante tu mets y en sortie de SAEM, mais ne faudrait-il pas mettre un y_est parce que t'as\n",
    "d√©j√† une variable y qui correspond aux vraies datas ? \n",
    "\"\"\"\n",
    "#mu,omega,sigma,y,mu_evolve,sigma_evolve,omega_evolve=SAEM(starting_w,starting_mu,starting_sigma,starting_y,phi_test,s_0,1500,method,M1=500)\n",
    "\n",
    "#alors oui des valeurs ne convergent pas, notamment celles de w mais dans l'article c'est pareil\n",
    "#et les mecs de l'ann√©e pr√©c√©dente aussi (et ils convergent moins bien pour les autres valeurs)\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "Montre les param√®tres et la tendance\n",
    "plot_viral_load(y,mu_,mu)\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "Graphique des param√®ters\n",
    "\n",
    "\n",
    "\n",
    "mu_evolve=np.array(mu_evolve)\n",
    "omega_evolve = np.array(omega_evolve)\n",
    "sigma_evolve = np.array(sigma_evolve)\n",
    "\n",
    "fig, axs = plt.subplots(3, 4, figsize=(10, 8))\n",
    "\n",
    "axs[0, 0].plot(mu_evolve[:,0], label='ln(P1)', color='blue')\n",
    "axs[0, 0].axhline(12, color='r', linestyle='--')  \n",
    "axs[0, 0].set_ylim(10,14)\n",
    "axs[0, 0].legend()\n",
    "\n",
    "axs[0, 1].plot(mu_evolve[:,1], label='ln(P2)', color='blue')\n",
    "axs[0, 1].axhline(8, color='r', linestyle='--')  \n",
    "axs[0, 1].set_ylim(6,10)\n",
    "axs[0, 1].legend()\n",
    "\n",
    "axs[0, 2].plot(mu_evolve[:,2], label='ln(lambda1)', color='blue')\n",
    "axs[0, 2].axhline(np.log(0.5), color='r', linestyle='--')  \n",
    "axs[0, 2].set_ylim(np.log(0.5)-2,np.log(0.5)+2)\n",
    "axs[0, 2].legend()\n",
    "\n",
    "axs[0, 3].plot(mu_evolve[:,3], label='ln(lambda2)', color='blue')\n",
    "axs[0, 3].axhline(np.log(0.05), color='r', linestyle='--')  \n",
    "axs[0, 3].set_ylim(np.log(0.05)-2,np.log(0.05)+2)\n",
    "axs[0, 3].legend()\n",
    "\n",
    "axs[1, 0].plot(omega_evolve[:,0], label='w_1', color='blue')\n",
    "axs[1, 0].axhline(0.3, color='r', linestyle='--')  \n",
    "axs[1, 0].set_ylim(0,1)  \n",
    "axs[1, 0].legend()\n",
    "\n",
    "axs[1, 1].plot(omega_evolve[:,1], label='w_2', color='blue')\n",
    "axs[1, 1].axhline(0.3, color='r', linestyle='--')  \n",
    "axs[1, 1].set_ylim(0,1)  \n",
    "axs[1, 1].legend()\n",
    "\n",
    "axs[1, 2].plot(omega_evolve[:,2], label='w_3', color='blue')\n",
    "axs[1, 2].axhline(0.3, color='r', linestyle='--')\n",
    "axs[1, 2].set_ylim(0,1)\n",
    "axs[1, 2].legend()\n",
    "\n",
    "axs[1, 3].plot(omega_evolve[:,3], label='w_4', color='blue')\n",
    "axs[1, 3].axhline(0.3, color='r', linestyle='--')\n",
    "axs[1, 3].set_ylim(0,1)  \n",
    "axs[1, 3].legend()\n",
    "\n",
    "axs[2, 0].plot(sigma_evolve, label='sigma', color='blue')\n",
    "axs[2, 0].axhline(0.065, color='r', linestyle='--')\n",
    "axs[1, 0].set_ylim(0,0.5)  \n",
    "axs[2, 0].legend()\n",
    "\n",
    "axs[2, 1].axis('off')\n",
    "axs[2, 2].axis('off')\n",
    "axs[2, 3].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Relative bias and relative root mean square error (RMSE) of parameters for the SAEM method. This being taken\n",
    "on nb_trials trials. \n",
    "\n",
    "\n",
    "nb_trials = 15\n",
    "iterations = 500\n",
    "method = 2\n",
    "SAEM_params = [starting_w, starting_mu, starting_sigma, starting_y, phi_test, s_0, iterations, method]\n",
    "real_params = [mu_, w, sigma]\n",
    "\n",
    "def plot_bias_RMSE(nb_trials, SAEM_params, real_params):\n",
    "    \n",
    "    mu_estimates = []\n",
    "    omega_estimates = []\n",
    "    sigma_estimates = []\n",
    "    \n",
    "    starting_w, starting_mu, starting_sigma, starting_y, phi_test, s_0, iterations, method = SAEM_params\n",
    "    mu_, w, sigma = real_params\n",
    "    \n",
    "    for _ in range(nb_trials):\n",
    "        mu_est, omega_est, sigma_est, _, _, _, _ = SAEM(starting_w, starting_mu, starting_sigma, starting_y, \n",
    "                                                        phi_test, s_0, iterations, method, M1=500)\n",
    "\n",
    "        mu_estimates.append(mu_est)\n",
    "        omega_estimates.append(omega_est)\n",
    "        sigma_estimates.append(sigma_est)\n",
    "        \n",
    "    mu_estimates = np.array(mu_estimates)\n",
    "    omega_estimates = np.array(omega_estimates)\n",
    "    sigma_estimates = np.array(sigma_estimates)\n",
    "\n",
    "    # Compute the bias and RMSE of each parameters\n",
    "    mu_bias = np.mean(mu_estimates - mu_, axis=0)\n",
    "    mu_rmse = np.sqrt(np.mean((mu_estimates - mu_)**2, axis=0))\n",
    "\n",
    "    omega_bias = np.mean(omega_estimates - w, axis=0)\n",
    "    omega_rmse = np.sqrt(np.mean((omega_estimates - w)**2, axis=0))\n",
    "\n",
    "    sigma_bias = np.mean(sigma_estimates - sigma)\n",
    "    sigma_rmse = np.sqrt(np.mean((sigma_estimates - sigma)**2))\n",
    "\n",
    "    print(\"Parameters \\t Relative Bias \\t\\t Relative RMSE\")\n",
    "    for i, param in enumerate([\"ln(P1)\", \"ln(P2)\", \"ln(ùúÜ1)\", \"ln(ùúÜ2)\"]):\n",
    "        print(f\"  {param}\\t     {np.abs(mu_bias[i]/mu_[i]):.2f}\\t\\t      {np.abs(mu_rmse[i]/mu_[i]):.2f}\")\n",
    "    for i, param in enumerate([\"omega1\", \"omega2\", \"omega3\", \"omega4\"]):\n",
    "        print(f\"  {param}\\t     {np.abs(omega_bias[i]/w[i]):.2f}\\t\\t      {np.abs(omega_rmse[i]/w[i]):.2f}\")\n",
    "    print(f\"  sigma\\t   \\t     {np.abs(sigma_bias/sigma):.2f}\\t\\t      {np.abs(sigma_rmse/sigma):.2f}\")\n",
    "    \n",
    "    return\n",
    "\n",
    "plot_bias_RMSE(nb_trials, SAEM_params, real_params)\n",
    " \n",
    "\"\"\"\n",
    "\n",
    "\"\"\" Je t'ai mis ce que donne le plot quand nb_trials = 15 et iterations = 500. Le programme prend \n",
    "son petit temps √† tourner. \n",
    "\n",
    "Parameters   Relative Bias     Relative RMSE\n",
    "  ln(P1)          0.02              0.02\n",
    "  ln(P2)          0.02              0.02\n",
    "  ln(ùúÜ1)          0.02              0.08\n",
    "  ln(ùúÜ2)          0.11              0.11\n",
    "  omega1          0.54              0.67\n",
    "  omega2          0.45              0.55\n",
    "  omega3          0.06              0.14\n",
    "  omega4          0.88              0.89\n",
    "  sigma           0.20              0.21\n",
    "  \n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#travailler sur l'acceptance rate de proposition_multidim_rw et proposition_unidim_rw avec le lambda\n",
    "#sur la premi√®re imputation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\text{Relative bias} = \\frac{\\sum_{i=1}^N x_i^{estimated}-x_{true}}{Nx_{true}}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\text{Relative RMSE} = \\frac{\\sqrt{\\frac{\\sum_{i=1}^N (x_i^{estimated}-x_{true})^2}{N}}}{x_{true}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The NLMEM (Nonlinear mixed effects model) is defined as follows : \n",
    "\n",
    "\\begin{equation*}\n",
    "\\begin{cases}\n",
    "y_{ij} &= f(\\phi_i, t_{ij}) + g\\left(\\phi_i, t_{ij}\\right)\\epsilon_{ij} \\\\\n",
    "\\epsilon_{ij} &\\sim \\mathcal{N}(0, \\sigma^2 I_{n_i}) \\\\\n",
    "\\phi_i &= X_i\\mu + b_i, \\text{ with }b_i \\sim \\mathcal{N}(0, \\Omega)\n",
    "\\end{cases}\n",
    "\\end{equation*}\n",
    "\n",
    "The parameters $\\theta$ of the models are : $\\theta = (\\mu,\\sigma^2,\\Omega)$.\n",
    "\n",
    "First, we will compute the complete likelihood of the $i$-th subject :\n",
    "\n",
    "$\n",
    "\\begin{aligned}\n",
    "\\textit{L}\\left(y_i^{obs},y_i^{cens},\\phi_i;\\theta\\right) &= \\log\\left(p\\left(y_i^{obs}, y_i^{cens},\\phi_i;\\theta\\right)\\right) \\\\\n",
    "&= \\sum_{(i,j)\\in I_{obs}} \\left(\\log\\left(p\\left(y_{ij}^{obs}|\\phi_i;\\theta\\right)\\right)\\right) + \\sum_{(i,j)\\in I_{cens}} \\left(\\log\\left(p\\left(y_{ij}^{cens}|\\phi_i;\\theta\\right)\\right)\\right)+ \\log\\left(p\\left(\\phi_i;\\theta\\right)\\right)\n",
    "\\end{aligned}\n",
    "$\n",
    "\n",
    "where : \n",
    "$\n",
    "\\begin{aligned}\n",
    "p\\left(y_{ij}^{obs}|\\phi_i;\\theta\\right) &= \\pi\\left(y_{ij};f\\left(\\phi_i,t_{ij}\\right),\\sigma^2g^2\\left(\\phi_i,t_{ij}\\right)\\right)\\mathbb{1}_{\\{y_{ij} \\geq LOQ\\}}, \\text{ if } (i,j)\\in I_{obs}\\\\\n",
    "p\\left(y_{ij}^{cens}|\\phi_i;\\theta\\right) &= \\pi\\left(y_{ij};f\\left(\\phi_i,t_{ij}\\right),\\sigma^2g^2\\left(\\phi_i,t_{ij}\\right)\\right)\\mathbb{1}_{\\{y_{ij} \\leq LOQ\\}}, \\text{ if } (i,j)\\in I_{cens}\n",
    "\\end{aligned}\n",
    "$ \n",
    "and $\\pi(x; m, v)$ is the probability density function of the Gaussian distribution with mean $m$ and variance $v$, evaluated at $x$.\n",
    "\n",
    "According to the NLMEM model, we have : \n",
    "$$\n",
    "\\forall i = 1, \\dots, N, \\;p\\left(\\phi_i;\\theta\\right) = \\frac{1}{\\sqrt{(2\\pi)^p\\det\\left(\\Omega\\right)}} \\exp\\left(-\\frac{1}{2}\\left(\\phi_i - X_i\\mu\\right)^T\\Omega^{-1}\\left(\\phi_i - X_i\\mu\\right)\\right)\n",
    "$$\n",
    "\n",
    "Then, we deduce that the complete likelihood of the $i$-th subject is equal to : \n",
    "\n",
    "$\n",
    "\\begin{aligned}\n",
    "\\textit{L}\\left(y_i^{obs},y_i^{cens},\\phi_i;\\theta\\right) &= -\\sum_{j=1}^{n_i} \\frac{\\left(y_{ij} - f\\left(\\phi_i, t_{ij}\\right)\\right)^2}{2\\sigma^2 g^2\\left(\\phi_i, t_{ij}\\right)} - \\frac{n_i}{2}\\left(\\log(2\\pi)+\\log\\left(\\sigma^2\\right) \\right) - \\sum_{j=1}^{n_i} \\log\\left(g\\left(\\phi_i, t_{ij}\\right)\\right) \\\\ &- \\frac{1}{2}\\left(p\\log(2\\pi)+ \\log\\det\\left(\\Omega\\right)\\right) -\\frac{1}{2}\\left(\\phi_i - X_i\\mu\\right)^T\\Omega^{-1}\\left(\\phi_i - X_i\\mu\\right)\n",
    "\\end{aligned}\n",
    "$\n",
    "\n",
    "And finaly, the complete likelihood of the model is equal to : \n",
    "\n",
    "$\n",
    "\\begin{aligned}\n",
    "\\textit{L}\\left(y,\\phi;\\theta\\right) &= -\\sum_{i=1}^N \\sum_{j=1}^{n_i} \\frac{\\left(y_{ij} - f\\left(\\phi_i, t_{ij}\\right)\\right)^2}{2\\sigma^2 g^2\\left(\\phi_i, t_{ij}\\right)} - \\frac{k}{2}\\left(\\log(2\\pi)+\\log\\left(\\sigma^2\\right) \\right) - \\sum_{i=1}^N \\sum_{j=1}^{n_i} \\log\\left(g\\left(\\phi_i, t_{ij}\\right)\\right) \\\\ &- \\frac{N}{2}\\left(p\\log(2\\pi)+ \\log\\det\\left(\\Omega\\right)\\right) -\\frac{1}{2}\\sum_{i=1}^N\\left(\\phi_i - X_i\\mu\\right)^T\\Omega^{-1}\\left(\\phi_i - X_i\\mu\\right)\n",
    "\\end{aligned}\n",
    "$\n",
    "\n",
    "where : \n",
    "$$\n",
    "k = \\sum_{i=1}^N n_i\n",
    "$$\n",
    "\n",
    "In the following, for the application, $\\Omega$ will be taken diagonally as $\\Omega = \\text{diag}(\\omega_1^2,\\omega_2^2,\\omega_3^2,\\omega_4^2)$, $g=1$ and $X_i$ independant of $i$ so we will write $X$.\n",
    "$\n",
    "\\begin{aligned}\n",
    "\\textit{L}\\left(y,\\phi;\\theta\\right) &= -\\sum_{i=1}^N \\sum_{j=1}^{n_i} \\frac{\\left(y_{ij} - f\\left(\\phi_i, t_{ij}\\right)\\right)^2}{2\\sigma^2} - \\frac{k}{2}\\left(\\log(2\\pi)+\\log\\left(\\sigma^2\\right) \\right) \\\\ &- \\frac{N}{2}\\left(p\\log(2\\pi)+ \\log\\det\\left(\\Omega\\right)\\right) -\\frac{1}{2}\\sum_{i=1}^N\\left(\\tilde{\\phi}_i^T\\tilde{\\omega} - \\phi_i^T\\Omega^{-1}X\\mu +(X\\mu)^T\\Omega^{-1}X\\mu\\right)\n",
    "\\end{aligned}\n",
    "$\n",
    "\n",
    "where we denote : \n",
    "$$\n",
    "\\tilde{\\phi}_i = \\begin{pmatrix}\\phi_{1i}^2\\\\\\dots\\\\\\phi_{4i}^2\\end{pmatrix} \\text{ and } \\tilde{\\omega} = \\begin{pmatrix}\\omega_1^{-2}\\\\\\dots\\\\\\omega_4^{-2}\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "Finaly, we can write the complete likelihood of the model in the following form : \n",
    "\n",
    "$$\n",
    "\\textit{L}\\left(y,\\phi;\\theta\\right) = -\\Lambda(\\theta) + \\langle S(y,\\phi),\\Phi(\\theta) \\rangle\n",
    "$$\n",
    "\n",
    "where : \n",
    "\\begin{equation*}\n",
    "\\begin{cases}\n",
    "\\Lambda(\\theta) &= \\frac{k}{2}\\left(\\log(2\\pi)+\\log\\left(\\sigma^2\\right)\\right) + \\frac{N}{2}\\left(p\\log(2\\pi)+ \\log\\det\\left(\\Omega\\right)\\right) + \\frac{1}{2}\\sum_{i=1}^N (X\\mu)^T\\Omega^{-1}X\\mu\\\\\n",
    "S(y,\\phi) &= \\left(\\sum_{i=1}^N \\phi_i, \\sum_{i=1}^N \\tilde{\\phi}_i, \\sum_{i=1}^N \\sum_{j=1}^{n_i}\\left(y_{ij} - f\\left(\\phi_i, t_{ij}\\right)\\right)^2 \\right)^T \\\\\n",
    "\\Phi(\\theta) &= \\left(\\frac{1}{2}\\Omega^{-1}X\\mu, -\\frac{1}{2}\\tilde{\\omega}, -\\frac{1}{2\\sigma^2}\\right)^T\n",
    "\\end{cases}\n",
    "\\end{equation*}\n",
    "\n",
    "Then, our complete likelihood belongs to the regular curved exponential family.\n",
    "\n",
    "Here, we have : \n",
    "$$\n",
    "f(\\phi_i,t_{ij}) = \\log_{10}\\left(P_{1i}\\text{e}^{-\\lambda_{1i}t_{ij}}+P_{2i}\\text{e}^{-\\lambda_{2i}t_{ij}}\\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imputation initiale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we can do is compute the better fitting curve to the observed data to initiate $\\phi_i$ for each patient. With the parameters we will find, we can thus impute the first censored values and it will give the first guess $y_{censored}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5.14289138 4.45817227 3.42778787 2.52243023 2.03999872 0.83023301]\n",
      "Real values : P1 = 12.4025407585337 log(lambda1) = -0.4822987721909587 P2 = 7.285360082437336 log(lambda2) = -2.4231198278389883\n",
      "P1 = 12.471576253446617 log(lambda1) = -0.34490872839448694 P2 = 7.185951910179049 log(lambda2) = -2.370249288610988\n",
      "0.8478887872604784\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "t=np.array([1,3,7,14,28,56])\n",
    "y_i,phi = viral_load(1)\n",
    "y_i = y_i[0]\n",
    "\n",
    "def model(t, P1, lambda1, P2, lambda2):\n",
    "    return np.log10(np.exp(P1) * np.exp(-lambda1 * t) + np.exp(P2) * np.exp(-lambda2 * t))\n",
    "\n",
    "print(y_i)\n",
    "initial_guess = [100, 1, 10, 0.05]  \n",
    "popt, pcov = curve_fit(model, t, y_i, p0=initial_guess)\n",
    "\n",
    "print(\"Real values : P1 =\", phi[0][0], \"log(lambda1) =\", phi[0][2], \"P2 =\", phi[0][1], \"log(lambda2) =\", phi[0][3])\n",
    "\n",
    "P1_opt, lambda1_opt, P2_opt, lambda2_opt = popt\n",
    "print(\"P1 =\", P1_opt, \"log(lambda1) =\", np.log(lambda1_opt), \"P2 =\", P2_opt, \"log(lambda2) =\", np.log(lambda2_opt))\n",
    "\n",
    "y_fit = model(t[-1], P1_opt, lambda1_opt, P2_opt, lambda2_opt)\n",
    "print(y_fit)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can compare the different imputations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\romai\\AppData\\Local\\Temp\\ipykernel_22868\\3868173010.py:46: OptimizeWarning: Covariance of the parameters could not be estimated\n",
      "  popt, pcov = curve_fit(model, time_observed, y[i][index_observed], p0=initial_guess)\n",
      "C:\\Users\\romai\\AppData\\Local\\Temp\\ipykernel_22868\\73455518.py:9: RuntimeWarning: overflow encountered in exp\n",
      "  return np.log10(np.exp(P1) * np.exp(-lambda1 * t) + np.exp(P2) * np.exp(-lambda2 * t))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error with 0, 4.640201902397899\n",
      "Error with 1.3, 0.8938375003131271\n",
      "Error with 2.6, 0.5274730982283551\n",
      "Error with fit, 0.41675873635462457\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(2)\n",
    "\n",
    "total_0 = 0\n",
    "total_mean = 0\n",
    "total_2 = 0\n",
    "total_fit = 0\n",
    "\n",
    "t = np.array([i for i in range(56)])\n",
    "\n",
    "iter = 200\n",
    "\n",
    "for _ in range(iter):\n",
    "\n",
    "    y, phi = viral_load(2, table_t=t)\n",
    "\n",
    "    imput_2 = np.copy(y)\n",
    "    imput_mean = np.copy(y)\n",
    "    imput_zero = np.copy(y)\n",
    "    imput_fit = np.copy(y)\n",
    "    N, K = imput_2.shape\n",
    "\n",
    "    error_0 = 0\n",
    "    error_mean = 0\n",
    "    error_2 = 0\n",
    "    error_fit = 0\n",
    "    number = 0\n",
    "\n",
    "    for i in range(N):\n",
    "        for j in range(K):\n",
    "            if y[i, j] <= 2.6:\n",
    "                number += 1\n",
    "                imput_2[i, j] = 2.6\n",
    "                error_2 += (y[i, j] - 2.6) ** 2\n",
    "                imput_mean[i, j] = 1.3\n",
    "                error_mean += (y[i, j] - 1.3) ** 2\n",
    "                imput_zero[i, j] = 0\n",
    "                error_0 += (y[i, j]) ** 2\n",
    "\n",
    "    for i in range(N):\n",
    "        censored_idx = np.where(y[i] <= 2.6)[0]  \n",
    "        initial_guess = [100, 1, 10, 0.05]\n",
    "        time_observed = [t[k] for k in range(26) if k not in censored_idx]\n",
    "        index_observed = [k for k in range(26) if k not in censored_idx]\n",
    "        \n",
    "        if len(time_observed) > 1: \n",
    "            popt, pcov = curve_fit(model, time_observed, y[i][index_observed], p0=initial_guess)\n",
    "            P1_opt, lambda1_opt, P2_opt, lambda2_opt = popt\n",
    "            for k in range(len(censored_idx)):  \n",
    "                imput_fit[i, censored_idx[k]] = model(t[censored_idx[k]], P1_opt, lambda1_opt, P2_opt, lambda2_opt)\n",
    "                if imput_fit[i, censored_idx[k]] >= 2.6:\n",
    "                    imput_fit[i, censored_idx[k]] = 2.6\n",
    "                elif imput_fit[i, censored_idx[k]] < 0:\n",
    "                    imput_fit[i, censored_idx[k]] = 0\n",
    "\n",
    "                error_fit += (y[i, censored_idx[k]] - imput_fit[i, censored_idx[k]]) ** 2\n",
    "\n",
    "    total_0 += error_0 / number\n",
    "    total_mean += error_mean / number\n",
    "    total_2 += error_2 / number\n",
    "    total_fit += error_fit / number\n",
    "\n",
    "print(f'Error with 0, {total_0 / iter}')\n",
    "print(f'Error with 1.3, {total_mean / iter}')\n",
    "print(f'Error with 2.6, {total_2 / iter}')\n",
    "print(f'Error with fit, {total_fit / iter}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
